{"cells":[{"cell_type":"code","source":["import numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport scipy.stats as stats\nimport time\nimport matplotlib.pyplot as plt\n\n# functions needed for further calculations:\n\ndef relative_diff(num,denum):\n  if denum==0:\n    return np.NaN\n  elif denum<0:\n    return -(num/denum-1)\n  else:\n    return num/denum-1\n\ndef array_diff(tr,ctr):\n  diff=np.array([])\n  if len(ctr[ctr<0])>0:\n    k=0\n    for c in ctr: \n      if c<0 and tr[k]<0:\n        diff=np.append(diff,-tr[k]+c)\n      else:\n        diff=np.append(diff,tr[k]-c)\n      k=k+1\n  else:\n    diff=tr-ctr\n  return diff\n\n# removes outliers with given quantile\ndef remove_outliers(df_customer,metric,quantile_for_outliers):\n  outliers_threshold=df_customer[metric].astype('float').quantile(quantile_for_outliers)\n  df_wo_outliers = df_customer.drop(df_customer[(df_customer[metric] >= outliers_threshold) | (df_customer[metric] < 0)].index)\n  return df_wo_outliers,outliers_threshold\n\n# return samples based on column and metrics names\ndef get_control_and_treatment_samples(df_customer,metric,variant_col,control_gr_name,treatment_gr_name):\n  control=df_customer[metric][df_customer[variant_col] == control_gr_name].values\n  treatment=df_customer[metric][df_customer[variant_col] == treatment_gr_name].values\n  return control, treatment\n\n# return z-test CI  \ndef get_z_test_CI(control,treatment):\n  ci_diff_primary = 1.96 * np.sqrt(np.square(np.std(treatment)) / len(treatment) + np.square(np.std(control)) / len(control))\n  return ci_diff_primary\n\n# bootstrap\ndef get_bootstrap_results(control,treatment,iterations=800):\n  sample_size=len(control)\n  boot_means_ctr=[]\n  boot_means_tr=[]\n  k = 0\n  boot_mean_diff = []\n  for b in np.arange(iterations):\n    bootstrap_controls=np.random.choice(control, size=sample_size, replace=True)\n    bootstrap_treatments=np.random.choice(treatment, size=sample_size, replace=True)\n    boot_mean_ctr=np.mean(bootstrap_controls)\n    boot_mean_tr=np.mean(bootstrap_treatments)\n    boot_means_ctr.append(boot_mean_ctr)\n    boot_means_tr.append(boot_mean_tr)\n    diff_means = boot_mean_tr - boot_mean_ctr\n    if diff_means<0:\n      k=k+1\n    boot_mean_diff.append(diff_means)\n  CI1_means = np.percentile(boot_mean_diff, [2.5, 97.5])\n  pval=2 * np.minimum(k, iterations - k) / iterations\n  ctr_mean=np.mean(boot_means_ctr)\n  tr_mean=np.mean(boot_means_tr)\n  mean_diff=relative_diff(tr_mean,ctr_mean)\n  ci_low=CI1_means[0]\n  ci_up=CI1_means[1]\n  if ctr_mean>0:\n    ci_prc_low=ci_low/ctr_mean\n    ci_prc_up=ci_up/ctr_mean\n  elif ctr_mean<0:\n    ci_prc_low=-ci_up/ctr_mean\n    ci_prc_up=-ci_low/ctr_mean\n  else:\n    ci_prc_low=0.0\n    ci_prc_up=0.0\n  return np.round(pval,4),np.round(ctr_mean,4),np.round(tr_mean,4),np.round(mean_diff,5),np.round(ci_prc_low,5),np.round(ci_prc_up,5)\n\n\n# get buckets and apply t_test\ndef get_buckets_results(control,treatment,buckets=150,confidence_level = 0.95):\n  buckets_means_ctr=[]\n  buckets_means_tr=[]\n  means_diff=[]\n  control_available_buckets=control\n  treatment_available_buckets=treatment\n  sample_size=int(np.floor(len(control)/buckets))\n  if sample_size<1000:\n    buckets=int(np.floor(len(control)/1000))\n    sample_size=int(np.floor(len(control)/buckets))\n  \n  for b in np.arange(buckets):\n    if (sample_size<=len(control_available_buckets)) & (sample_size<=len(treatment_available_buckets)):\n      control_idx=np.random.randint(0, len(control_available_buckets), sample_size)\n      test_idx=np.random.randint(0, len(treatment_available_buckets), sample_size)\n      sample_ctr=control_available_buckets[control_idx]\n      sample_tr=treatment_available_buckets[test_idx]\n      tr_mean=np.mean(sample_tr)\n      ctr_mean=np.mean(sample_ctr)\n      means_diff.append(tr_mean-ctr_mean)\n      buckets_means_ctr.append(ctr_mean)\n      buckets_means_tr.append(tr_mean)\n      control_available_buckets = np.delete(control_available_buckets, control_idx)\n      treatment_available_buckets= np.delete(treatment_available_buckets, test_idx)\n\n  pval_mean=stats.ttest_ind(buckets_means_ctr,buckets_means_tr).pvalue\n  mean_buckets_tr=np.mean(buckets_means_tr)\n  mean_buckets_ctr=np.mean(buckets_means_ctr)\n  \n  degrees_freedom = len(means_diff) - 1\n  sample_mean = np.mean(means_diff)\n  sample_standard_error = stats.sem(means_diff)\n  confidence_interval = stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_standard_error)\n  ci_low=confidence_interval[0]\n  ci_up=confidence_interval[1]\n  if mean_ctr>0:\n    ci_prc_low=ci_low/mean_buckets_ctr\n    ci_prc_up=ci_up/mean_buckets_ctr\n  elif mean_ctr<0:\n    ci_prc_low=-ci_up/mean_buckets_ctr\n    ci_prc_up=-ci_low/mean_buckets_ctr\n  else:\n    ci_prc_low=0.0\n    ci_prc_up=0.0\n  \n   \n  return np.round(pval_mean,4),np.round(mean_buckets_ctr,4),np.round(mean_buckets_tr,4),np.round(relative_diff(mean_buckets_tr,mean_buckets_ctr), 5),np.round(ci_prc_low,5),np.round(ci_prc_up,5)\n\n\n# return t-test pval,CIs, mean diffs\ndef get_t_test_results(ctr,tr,confidence_level = 0.95):\n  ctr=ctr.astype('float')\n  tr=tr.astype('float')\n  pval=stats.ttest_ind(ctr,tr).pvalue\n  mean_tr=np.mean(tr)\n  mean_ctr=np.mean(ctr)\n  if len(tr)>len(ctr):\n    tr=np.random.choice(tr, size=len(ctr), replace=False)\n  else:\n    ctr=np.random.choice(ctr, size=len(tr), replace=False)\n  diff=array_diff(tr,ctr)\n  degrees_freedom = len(diff) - 1\n  sample_mean = np.mean(diff)\n  sample_standard_error = stats.sem(diff)\n  confidence_interval = stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_standard_error)\n  ci_low=confidence_interval[0]\n  ci_up=confidence_interval[1]\n  if mean_ctr>0:\n    ci_prc_low=ci_low/mean_ctr\n    ci_prc_up=ci_up/mean_ctr\n  elif mean_ctr<0:\n    ci_prc_low=-ci_up/mean_ctr\n    ci_prc_up=-ci_low/mean_ctr\n  else:\n    ci_prc_low=0.0\n    ci_prc_up=0.0\n  \n  return np.round(pval,4),np.round(mean_tr,4),np.round(mean_ctr,4),np.round(relative_diff(mean_tr,mean_ctr),5),np.round(ci_prc_low,5),np.round(ci_prc_up,5)\n\ndef get_chi2_test_results(control_num,control_denum,treatment_num,treatment_denum):\n  T = np.array([[np.sum(control_num), np.sum(control_denum)-np.sum(control_num)], [np.sum(treatment_num), np.sum(treatment_denum)-np.sum(treatment_num)]])\n  conv_pval=np.round(stats.chi2_contingency(T,correction=False)[1],5)\n  return conv_pval\n\ndef get_bootstrap_results_for_conversions(control_num_arr, control_denum_arr, tr_num_arr, tr_denum_arr, bootstrap_iterations=800):\n  bootstrap_sample_size=len(control_denum_arr)\n  boot_means_ctr=[]\n  boot_means_tr=[]\n  boot_mean_diff=[]\n  k=0\n  for b in np.arange(bootstrap_iterations):\n    idx_control=np.random.choice(np.arange(len(control_denum_arr)), size=bootstrap_sample_size, replace=True)\n    control_denum=np.sum(control_denum_arr[idx_control])\n    control_num=np.sum(control_num_arr[idx_control])\n    idx_tr=np.random.choice(np.arange(len(tr_denum_arr)), size=bootstrap_sample_size, replace=True)\n    tr_denum=np.sum(tr_denum_arr[idx_tr])\n    tr_num=np.sum(tr_num_arr[idx_tr])\n    boot_mean_ctr=control_num/control_denum\n    boot_mean_tr=tr_num/tr_denum\n    boot_means_ctr.append(control_num/control_denum)\n    boot_means_tr.append(tr_num/tr_denum)  \n    diff_means = boot_mean_tr - boot_mean_ctr\n    if diff_means<0:\n      k=k+1\n    boot_mean_diff.append(diff_means)\n  CI1_means = np.percentile(boot_mean_diff, [2.5, 97.5])\n  pval=2 * np.minimum(k, bootstrap_iterations - k) / bootstrap_iterations\n  ctr_mean=np.mean(boot_means_ctr)\n  tr_mean=np.mean(boot_means_tr)\n  mean_diff=relative_diff(tr_mean,ctr_mean)\n  ci_low=CI1_means[0]\n  ci_up=CI1_means[1]\n  ci_prc_low=ci_low/ctr_mean\n  ci_prc_up=ci_up/ctr_mean\n  return np.round(pval,4),np.round(ctr_mean,4),np.round(tr_mean,4),np.round(mean_diff,5),np.round(ci_prc_low,5),np.round(ci_prc_up,5)\n  \ndef get_buckets_results_for_conversions(control_num_arr, control_denum_arr, tr_num_arr, tr_denum_arr,buckets=150,confidence_level = 0.95):\n  buckets_means_ctr=[]\n  buckets_means_tr=[]\n  means_diff=[]\n  control_num_available_buckets=control_num_arr\n  treatment_num_available_buckets=tr_num_arr\n  control_denum_available_buckets=control_denum_arr\n  treatment_denum_available_buckets=tr_denum_arr\n  sample_size=int(np.floor(len(control_num_arr)/buckets))\n  if sample_size<4000:\n    buckets=int(np.floor(len(control_num_arr)/4000))\n    sample_size=int(np.floor(len(control_num_arr)/buckets))\n  \n  for b in np.arange(buckets):\n    if (sample_size<=len(control_num_available_buckets)) & (sample_size<=len(treatment_num_available_buckets)):\n      control_idx=np.random.randint(0, len(control_num_available_buckets), sample_size)\n      test_idx=np.random.randint(0, len(treatment_num_available_buckets), sample_size)\n      sample_ctr=control_num_available_buckets[control_idx]/control_denum_available_buckets[control_idx]\n      sample_tr=treatment_num_available_buckets[test_idx]/treatment_denum_available_buckets[test_idx]\n      tr_mean=np.mean(sample_tr)\n      ctr_mean=np.mean(sample_ctr)\n      means_diff.append(tr_mean-ctr_mean)\n      buckets_means_ctr.append(ctr_mean)\n      buckets_means_tr.append(tr_mean)\n      control_num_available_buckets = np.delete(control_num_available_buckets, control_idx)\n      treatment_num_available_buckets= np.delete(treatment_num_available_buckets, test_idx)\n      control_denum_available_buckets = np.delete(control_denum_available_buckets, control_idx)\n      treatment_denum_available_buckets= np.delete(treatment_denum_available_buckets, test_idx)\n\n  pval_mean=stats.ttest_ind(buckets_means_ctr,buckets_means_tr).pvalue\n  mean_buckets_tr=np.mean(buckets_means_tr)\n  mean_buckets_ctr=np.mean(buckets_means_ctr)\n  \n  \n  degrees_freedom = len(means_diff) - 1\n  sample_mean = np.mean(means_diff)\n  sample_standard_error = stats.sem(means_diff)\n  confidence_interval = stats.t.interval(confidence_level, degrees_freedom, sample_mean, sample_standard_error)\n  ci_low=confidence_interval[0]\n  ci_up=confidence_interval[1]\n  ci_prc_low=ci_low/mean_buckets_ctr\n  ci_prc_up=ci_up/mean_buckets_ctr\n  \n   \n  return np.round(pval_mean,4),np.round(mean_buckets_ctr,4),np.round(mean_buckets_tr,4),np.round(relative_diff(mean_buckets_tr,mean_buckets_ctr), 5), np.round(ci_prc_low,5), np.round(ci_prc_up,5) \n\n\ndef get_bootstrap_results_for_conversions_mde(control_num_arr, control_denum_arr, uplift=0.0, bootstrap_iterations=800):\n  bootstrap_sample_size=len(control_denum_arr)\n  boot_means_ctr=[]\n  boot_means_tr=[]\n  boot_mean_diff=[]\n  k=0\n  for b in np.arange(bootstrap_iterations):\n    idx_control=np.random.choice(np.arange(len(control_denum_arr)), size=bootstrap_sample_size, replace=True)\n    control_denum=np.sum(control_denum_arr[idx_control])\n    control_num=np.sum(control_num_arr[idx_control])\n    idx_tr=np.random.choice(np.arange(len(control_denum_arr)), size=bootstrap_sample_size, replace=True)\n    tr_denum=np.sum(control_denum_arr[idx_tr])\n    tr_num=np.sum(control_num_arr[idx_tr])\n    boot_mean_ctr=control_num/control_denum\n    boot_mean_tr=tr_num/tr_denum*(1+uplift)\n    diff_means = boot_mean_tr - boot_mean_ctr\n    if diff_means<0:\n      k=k+1\n  pval=2 * np.minimum(k, bootstrap_iterations - k) / bootstrap_iterations\n  return np.round(pval,4)\n  \n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b5cea08f-1ab6-475b-83f0-fb350de57d58","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def main_ab_test_calculation_function(day, calc_start_date, calc_end_date, metrics_columns, need_bootstrap, need_buckets, need_mde, proportions_metrics_flag, proportions_columns,ratio_metrics_flag,ratio_columns, query):\n  df_results=pd.DataFrame()\n  print(day)\n  start_time = time.time()\n\n  df_customer = dwhRead(query)\n  df_customer = df_customer.toPandas()\n  df_customer=df_customer.fillna(0)\n  print(\" %s minutes needed for Query calculations \" % (np.round((time.time() - start_time)/60,1)))\n  start_time = time.time()\n\n  for metric in metrics_columns:\n    print(metric,'start calculations')\n    #     remove outliers \n    df_wo_outliers,outliers_threshold = remove_outliers(df_customer,metric,quantile_for_outliers)\n\n    #     get needed data from DF\n    control,treatment = get_control_and_treatment_samples(df_customer,metric,variant_col,control_gr_name,treatment_gr_name)\n    control_wo_outliers,treatment_wo_outliers = get_control_and_treatment_samples(df_wo_outliers,metric,variant_col,control_gr_name,treatment_gr_name)\n    #     T-test pvalue calculations\n    ttest_pval, ttest_mean_tr, ttest_mean_ctr, ttest_mean_diff, ttest_ci_prc_low, ttest_ci_prc_up = get_t_test_results(control,treatment)\n    ttest_pval_wo_outliers, ttest_mean_tr_wo_outliers, ttest_mean_ctr_wo_outliers, ttest_mean_diff_wo_outliers, ttest_ci_prc_low_wo_outliers, ttest_ci_prc_up_wo_outliers = get_t_test_results(control_wo_outliers,treatment_wo_outliers)\n\n    #  MW test calculations\n    mw_test_pval=stats.mannwhitneyu(control,treatment).pvalue\n\n    #  Mean, median and its differences\n    control_mean=np.round(control.mean(),4)\n    treatment_mean=np.round(treatment.mean(),4)\n    mean_diff=np.round(relative_diff(treatment_mean,control_mean),4)\n\n    control_mean_wo_outliers=np.round(control_wo_outliers.mean(),4)\n    treatment_mean_wo_outliers=np.round(treatment_wo_outliers.mean(),4)\n    mean_diff_wo_outliers=np.round(relative_diff(treatment_mean_wo_outliers,control_mean_wo_outliers),4)\n\n    control_median=np.median(control)\n    treatment_median=np.median(treatment)\n    median_diff=np.round(relative_diff(treatment_median,control_median),4)\n\n#     #     CI bounds calculation\n#     ci_diff_primary = get_z_test_CI(control,treatment)\n#     ci_diff_primary_wo_outliers = get_z_test_CI(control_wo_outliers,treatment_wo_outliers)\n\n    print(\" %s minutes needed for usual tests calculations \" % (np.round((time.time() - start_time)/60,1)))\n\n    # bootstrap\n    if need_bootstrap:\n      btstrp_pval, btstrp_ctr_mean, btstrp_tr_mean, btstrp_mean_diff, btstrp_ci_prc_low, btstrp_ci_prc_up = get_bootstrap_results(control,treatment,bootstrap_iterations)\n    else:\n      btstrp_pval = np.NaN\n      btstrp_ctr_mean = np.NaN\n      btstrp_tr_mean = np.NaN\n      btstrp_mean_diff = np.NaN\n      btstrp_ci_prc_low = np.NaN\n      btstrp_ci_prc_up = np.NaN\n    if need_boostrap_wo_outliers:\n      btstrp_pval_wo_outliers, btstrp_ctr_mean_wo_outliers, btstrp_tr_mean_wo_outliers, btstrp_mean_diff_wo_outliers, btstrp_ci_prc_low_wo_outliers, btstrp_ci_prc_up_wo_outliers = get_bootstrap_results(control_wo_outliers,treatment_wo_outliers,bootstrap_iterations)\n    else:\n      btstrp_pval_wo_outliers = np.NaN \n      btstrp_ctr_mean_wo_outliers  = np.NaN \n      btstrp_tr_mean_wo_outliers  = np.NaN\n      btstrp_mean_diff_wo_outliers = np.NaN\n      btstrp_ci_prc_low_wo_outliers = np.NaN\n      btstrp_ci_prc_up_wo_outliers  = np.NaN\n\n\n\n    print(\" %s minutes needed for usual+bootstrap tests calculations \" % (np.round((time.time() - start_time)/60,1)))\n\n    # buckets+t_test\n    if need_buckets:\n      buckets_pval, buckets_ctr_mean, buckets_tr_mean, buckets_mean_diff, buckets_ci_prc_low, buckets_ci_prc_up = get_buckets_results(control,treatment,buckets_num)\n    else:\n      buckets_pval = np.NaN\n      buckets_ctr_mean = np.NaN\n      buckets_tr_mean = np.NaN\n      buckets_mean_diff = np.NaN\n      buckets_ci_prc_low = np.NaN\n      buckets_ci_prc_up = np.NaN\n    if need_buckets_wo_outliers:\n      buckets_pval_wo_outliers, buckets_ctr_mean_wo_outliers, buckets_tr_mean_wo_outliers, buckets_mean_diff_wo_outliers, buckets_ci_prc_low_wo_outliers, buckets_ci_prc_up_wo_outliers = get_buckets_results(control_wo_outliers,treatment_wo_outliers,buckets_num)\n    else:\n      buckets_pval_wo_outliers = np.NaN\n      buckets_ctr_mean_wo_outliers = np.NaN\n      buckets_tr_mean_wo_outliers = np.NaN\n      buckets_mean_diff_wo_outliers = np.NaN\n      buckets_ci_prc_low_wo_outliers = np.NaN\n      buckets_ci_prc_up_wo_outliers = np.NaN\n\n    print(\" %s minutes needed for usual+bootstrap+buckets tests calculations \" % (np.round((time.time() - start_time)/60,1)))    \n    if need_mde:\n      btstrp_stop=False\n      ttest_wo_outliers_stop=False\n      btstrp_mde=1.0\n      ttest_wo_outliers_mde=1.0\n      for uplift in [0.001,0.0025,0.005,0.01,0.03,0.05,0.1]:\n        treatment_uplifted=control*(1+uplift)\n        treatment_wo_outliers_uplifted=control_wo_outliers*(1+uplift)\n        if not ttest_wo_outliers_stop:\n          ttest_pval_wo_outliers_uplifted, ttest_mean_tr_wo_outliers_uplifted, ttest_mean_ctr_wo_outliers_uplifted, ttest_mean_diff_wo_outliers_uplifted, ttest_ci_prc_low_wo_outliers_uplifted, ttest_ci_prc_up_wo_outliers_uplifted = get_t_test_results(control_wo_outliers,treatment_wo_outliers_uplifted)\n        if not btstrp_stop:\n          btstrp_pval_uplifted, btstrp_ctr_mean_uplifted, btstrp_tr_mean_uplifted, btstrp_mean_diff_uplifted, btstrp_ci_prc_low_uplifted, btstrp_ci_prc_up_uplifted = get_bootstrap_results(control,treatment_uplifted,bootstrap_iterations) \n        if ttest_pval_wo_outliers_uplifted<=0.05 and not ttest_wo_outliers_stop :\n          ttest_wo_outliers_stop=True\n          ttest_wo_outliers_mde=uplift\n        if btstrp_pval_uplifted<=0.05 and not btstrp_stop:\n          btstrp_stop=True\n          btstrp_mde=uplift\n\n    print(\" %s minutes needed for usual+bootstrap+buckets+mde tests calculations \" % (np.round((time.time() - start_time)/60,1)))    \n\n\n\n\n\n    #     collect results and append it to results df\n    results_for_day = pd.Series(data={'experiment_name':experiment_name,'dt':day,'metric':metric\n           ,'metric_type': 'continuous'\n           ,'mean_control':control_mean\n           ,'mean_treatment':treatment_mean\n           ,'mean_diff':mean_diff\n           ,'mean_control_wo_outliers':control_mean_wo_outliers\n           ,'mean_treatment_wo_outliers':treatment_mean_wo_outliers\n           ,'mean_diff_wo_outliers':mean_diff_wo_outliers\n           ,'median_control': control_median\n           ,'median_treatment':treatment_median\n           ,'median_diff':median_diff\n           ,'ttest_pval':ttest_pval\n           ,'ttest_mean_diff':ttest_mean_diff\n           ,'ttest_ci_prc_low':ttest_ci_prc_low\n           ,'ttest_ci_prc_up':ttest_ci_prc_up\n           ,'ttest_wo_outliers_pval':ttest_pval_wo_outliers\n           ,'ttest_wo_outliers_mean_diff':ttest_mean_diff_wo_outliers\n           ,'ttest_wo_outliers_ci_prc_low':ttest_ci_prc_low_wo_outliers\n           ,'ttest_wo_outliers_ci_prc_up':ttest_ci_prc_up_wo_outliers\n           ,'btstrp_pval':btstrp_pval\n           ,'btstrp_mean_diff':btstrp_mean_diff\n           ,'btstrp_ci_prc_low':btstrp_ci_prc_low\n           ,'btstrp_ci_prc_up':btstrp_ci_prc_up\n           ,'btstrp_wo_outliers_pval':btstrp_pval_wo_outliers\n           ,'btstrp_wo_outliers_mean_diff':btstrp_mean_diff_wo_outliers\n           ,'btstrp_wo_outliers_ci_prc_low':btstrp_ci_prc_low_wo_outliers\n           ,'btstrp_wo_outliers_ci_prc_up':btstrp_ci_prc_up_wo_outliers\n           ,'buckets_pval':buckets_pval\n           ,'buckets_mean_diff':buckets_mean_diff\n           ,'buckets_ci_prc_low':buckets_ci_prc_low\n           ,'buckets_ci_prc_up':buckets_ci_prc_up\n           ,'buckets_wo_outliers_pval':buckets_pval_wo_outliers\n           ,'buckets_wo_outliers_mean_diff':buckets_mean_diff_wo_outliers\n           ,'buckets_wo_outliers_ci_prc_low':buckets_ci_prc_low_wo_outliers\n           ,'buckets_wo_outliers_ci_prc_up':buckets_ci_prc_up_wo_outliers\n           ,'MW_pval':mw_test_pval\n           ,'chi2_pval':np.NaN                         \n           ,'outliers_percentile':quantile_for_outliers\n           ,'outliers_threshold':outliers_threshold\n           ,'calculations_time':calculations_time\n           ,'mde_bootstrap':btstrp_mde\n           ,'mde_ttest_wo_outliers':ttest_wo_outliers_mde\n           ,'units_control': len(control)\n           ,'units_treatment': len(treatment)\n           ,'srm_pval': np.round(stats.chisquare([len(control),len(treatment)])[1],4)\n          },name=calculations_time)\n    df_results=df_results.append(results_for_day, ignore_index=False)\n  if proportions_metrics_flag:\n    for num_col in proportions_columns.keys():\n      denum_col=proportions_columns[num_col]\n      control_num,treatment_num = get_control_and_treatment_samples(df_customer,num_col,variant_col,control_gr_name,treatment_gr_name)\n      control_denum,treatment_denum = get_control_and_treatment_samples(df_customer,denum_col,variant_col,control_gr_name,treatment_gr_name)\n      proportions_control=np.round(np.sum(control_num)/np.sum(control_denum),4)\n      proportions_treatment=np.round(np.sum(treatment_num)/np.sum(treatment_denum),4)\n      proportions_diff= np.round(((proportions_treatment/proportions_control)-1),4)\n      conv_pval=get_chi2_test_results(control_num,control_denum,treatment_num,treatment_denum)\n\n      if need_mde:\n        ztest_stop=False\n        ztest_mde=1.0\n        conv_pval_uplifted=1.0\n        for uplift in [0.001,0.0025,0.005,0.01,0.03,0.05,0.1]:\n          treatment_uplifted_num=np.sum(control_num)*(1+uplift)\n          treatment_uplifted_denum=np.sum(control_denum)\n          if not ztest_stop and treatment_uplifted_num < treatment_uplifted_denum:\n            T = np.array([[np.sum(control_num), np.sum(control_denum)-np.sum(control_num)], [treatment_uplifted_num, treatment_uplifted_denum-treatment_uplifted_num]])\n            conv_pval_uplifted=np.round(stats.chi2_contingency(T,correction=False)[1],5)\n          if conv_pval_uplifted<=0.05 and not ztest_stop:\n            ztest_stop=True\n            ztest_mde=uplift\n\n\n      results_for_day = pd.Series(data={'experiment_name':experiment_name,'dt':day\n           ,'metric':(num_col+'/'+denum_col)\n           ,'metric_type': 'proportion'\n           ,'mean_control':proportions_control\n           ,'mean_treatment':proportions_treatment\n           ,'mean_diff':proportions_diff\n           ,'mean_control_wo_outliers':np.NaN\n           ,'mean_treatment_wo_outliers':np.NaN\n           ,'mean_diff_wo_outliers':np.NaN\n           ,'median_control': np.NaN\n           ,'median_treatment':np.NaN\n           ,'median_diff':np.NaN\n           ,'ttest_pval':np.NaN\n           ,'ttest_mean_diff':np.NaN\n           ,'ttest_ci_prc_low':np.NaN\n           ,'ttest_ci_prc_up':np.NaN\n           ,'ttest_wo_outliers_pval':np.NaN\n           ,'ttest_wo_outliers_mean_diff':np.NaN\n           ,'ttest_wo_outliers_ci_prc_low':np.NaN\n           ,'ttest_wo_outliers_ci_prc_up':np.NaN\n           ,'btstrp_pval':np.NaN\n           ,'btstrp_mean_diff':np.NaN\n           ,'btstrp_ci_prc_low':np.NaN\n           ,'btstrp_ci_prc_up':np.NaN\n           ,'btstrp_wo_outliers_pval':np.NaN\n           ,'btstrp_wo_outliers_mean_diff':np.NaN\n           ,'btstrp_wo_outliers_ci_prc_low':np.NaN\n           ,'btstrp_wo_outliers_ci_prc_up':np.NaN\n           ,'buckets_pval':np.NaN\n           ,'buckets_mean_diff':np.NaN\n           ,'buckets_ci_prc_low':np.NaN\n           ,'buckets_ci_prc_up':np.NaN\n           ,'buckets_wo_outliers_pval':np.NaN\n           ,'buckets_wo_outliers_mean_diff':np.NaN\n           ,'buckets_wo_outliers_ci_prc_low':np.NaN\n           ,'buckets_wo_outliers_ci_prc_up':np.NaN\n           ,'MW_pval':np.NaN\n           ,'chi2_pval':conv_pval                         \n           ,'outliers_percentile':np.NaN\n           ,'outliers_threshold':np.NaN\n           ,'calculations_time':calculations_time\n           ,'mde_bootstrap':ztest_mde\n           ,'mde_ttest_wo_outliers':ztest_mde\n           ,'units_control': np.sum(control_denum)\n           ,'units_treatment': np.sum(treatment_denum)\n           ,'srm_pval': np.round(stats.chisquare([np.sum(control_denum),np.sum(treatment_denum)])[1],4)                           \n          },name=calculations_time)\n      df_results=df_results.append(results_for_day, ignore_index=False)\n      print(\" %s minutes needed for proportions usual tests calculations \" % (np.round((time.time() - start_time)/60,1)))\n\n#       add\n  if ratio_metrics_flag:\n    for num_col in ratio_columns.keys():\n      denum_col=ratio_columns[num_col]\n      control_num,treatment_num = get_control_and_treatment_samples(df_customer,num_col,variant_col,control_gr_name,treatment_gr_name)\n      control_denum,treatment_denum = get_control_and_treatment_samples(df_customer,denum_col,variant_col,control_gr_name,treatment_gr_name)\n      ratio_control=np.round(np.sum(control_num)/np.sum(control_denum),4)\n      ratio_treatment=np.round(np.sum(treatment_num)/np.sum(treatment_denum),4)\n      ratio_diff= np.round(relative_diff(ratio_treatment,ratio_control),4)\n      btstrp_pval, btstrp_ctr_mean, btstrp_tr_mean, btstrp_mean_diff, btstrp_ci_prc_low, btstrp_ci_prc_up = get_bootstrap_results_for_conversions(control_num, control_denum, treatment_num, treatment_denum, bootstrap_iterations)\n      print(\" %s minutes needed for ratio bootstrap tests calculations \" % (np.round((time.time() - start_time)/60,1)))\n\n#       bucket test if requested\n      if need_buckets:\n        buckets_pval, buckets_ctr_mean, buckets_tr_mean, buckets_mean_diff, buckets_ci_prc_low, buckets_ci_prc_up = get_buckets_results_for_conversions(control_num, control_denum, treatment_num, treatment_denum, buckets_num)\n      else:\n        buckets_pval = np.NaN\n        buckets_ctr_mean = np.NaN\n        buckets_tr_mean = np.NaN\n        buckets_mean_diff = np.NaN\n        buckets_ci_prc_low = np.NaN\n        buckets_ci_prc_up = np.NaN\n      print(\" %s minutes needed for ratio bootstrap+buckets tests calculations \" % (np.round((time.time() - start_time)/60,1)))\n\n      if need_mde:\n        btstrp_stop=False\n        btstrp_mde=1.0\n        for uplift in [0.001,0.0025,0.005,0.01,0.03,0.05,0.1]:\n          if not btstrp_stop:\n            btstrp_pval_uplifted = get_bootstrap_results_for_conversions_mde(control_num, control_denum, uplift, bootstrap_iterations)\n          if btstrp_pval_uplifted<=0.05 and not btstrp_stop:\n            btstrp_stop=True\n            btstrp_mde=uplift\n\n      print(\" %s minutes needed for ratio bootstrap+buckets and MDE tests calculations \" % (np.round((time.time() - start_time)/60,1)))\n\n\n      results_for_day = pd.Series(data={'experiment_name':experiment_name,'dt':day\n           ,'metric':(num_col+'/'+denum_col)\n           ,'metric_type': 'ratio'\n           ,'mean_control':ratio_control\n           ,'mean_treatment':ratio_treatment\n           ,'mean_diff':ratio_diff\n           ,'mean_control_wo_outliers':np.NaN\n           ,'mean_treatment_wo_outliers':np.NaN\n           ,'mean_diff_wo_outliers':np.NaN\n           ,'median_control': np.NaN\n           ,'median_treatment':np.NaN\n           ,'median_diff':np.NaN\n           ,'ttest_pval':np.NaN\n           ,'ttest_mean_diff':np.NaN\n           ,'ttest_ci_prc_low':np.NaN\n           ,'ttest_ci_prc_up':np.NaN\n           ,'ttest_wo_outliers_pval':np.NaN\n           ,'ttest_wo_outliers_mean_diff':np.NaN\n           ,'ttest_wo_outliers_ci_prc_low':np.NaN\n           ,'ttest_wo_outliers_ci_prc_up':np.NaN\n           ,'btstrp_pval':btstrp_pval\n           ,'btstrp_mean_diff':btstrp_mean_diff\n           ,'btstrp_ci_prc_low':btstrp_ci_prc_low\n           ,'btstrp_ci_prc_up':btstrp_ci_prc_up\n           ,'btstrp_wo_outliers_pval':np.NaN\n           ,'btstrp_wo_outliers_mean_diff':np.NaN\n           ,'btstrp_wo_outliers_ci_prc_low':np.NaN\n           ,'btstrp_wo_outliers_ci_prc_up':np.NaN\n           ,'buckets_pval':buckets_pval\n           ,'buckets_mean_diff':buckets_mean_diff\n           ,'buckets_ci_prc_low':buckets_ci_prc_low\n           ,'buckets_ci_prc_up':buckets_ci_prc_up\n           ,'buckets_wo_outliers_pval':np.NaN\n           ,'buckets_wo_outliers_mean_diff':np.NaN\n           ,'buckets_wo_outliers_ci_prc_low':np.NaN\n           ,'buckets_wo_outliers_ci_prc_up':np.NaN\n           ,'MW_pval':np.NaN\n           ,'chi2_pval':np.NaN                         \n           ,'outliers_percentile':np.NaN\n           ,'outliers_threshold':np.NaN\n           ,'calculations_time':calculations_time\n           ,'mde_bootstrap': btstrp_mde\n           ,'mde_ttest_wo_outliers':np.NaN\n           ,'units_control': len(control_denum)\n           ,'units_treatment': len(treatment_denum)\n           ,'srm_pval': np.round(stats.chisquare([len(control_denum),len(treatment_denum)])[1],4)\n          },name=calculations_time)\n      df_results=df_results.append(results_for_day, ignore_index=False)\n\n  print(\" %s minutes needed for Tests calculations \" % (np.round((time.time() - start_time)/60,1)))\n  print(day,'-done')\n  return df_results\n    \n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8fa97686-aed8-4b6d-b86a-a510d3ab4a37","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def main_function_for_sample_size_calculations(query, mde, w, treatment_share_percent, pvals, pval_counter, proportions_columns, ratio_columns, continuous_metric_name, continuous_metric_flag, proportions_metric_flag, ratio_metric_flag):\n  df_customer = dwhRead(query)\n  df_customer = df_customer.toPandas()\n  df_customer= df_customer.sample(frac=treatment_share_percent, replace=False, random_state=1)\n  s_size=len(df_customer)\n\n  \n  if continuous_metric_flag:\n    control=df_customer[continuous_metric_name].values\n    control_uplifted=control*(1+mde)\n    pval, btstrp_ctr_mean_uplifted, btstrp_tr_mean_uplifted, btstrp_mean_diff_uplifted, btstrp_ci_prc_low_uplifted, btstrp_ci_prc_up_uplifted = get_bootstrap_results(control,control_uplifted,bootstrap_iterations) \n    pvals.update({w: pval})\n    if pval<0.05:\n      pval_counter+=1\n    else:\n      pval_counter=0\n  \n  if proportions_metric_flag:\n    if len(proportions_columns)>1:\n      raise ValueError('You should input only one proportion metric')\n    num_name=list(proportions_columns.keys())[0]\n    denum_name=proportions_columns[num_name]\n    control_num=df_customer[num_name].values\n    control_denum=df_customer[denum_name].values\n    treatment_uplifted_num=np.sum(control_num)*(1+mde)\n    treatment_uplifted_denum=np.sum(control_denum)\n    T = np.array([[np.sum(control_num), np.sum(control_denum)-np.sum(control_num)], [treatment_uplifted_num, treatment_uplifted_denum-treatment_uplifted_num]])\n    pval=np.round(stats.chi2_contingency(T,correction=False)[1],5)\n    pvals.update({w: pval})\n    if pval<0.05:\n      pval_counter+=1\n    else:\n      pval_counter=0\n  \n  if ratio_metric_flag:\n    if len(ratio_columns)>1:\n      raise ValueError('You should input only one ratio metric')\n    \n    num_name=list(ratio_columns.keys())[0]\n    denum_name=ratio_columns[num_name]\n    control_num=df_customer[num_name].values\n    control_denum=df_customer[denum_name].values\n    pval= get_bootstrap_results_for_conversions_mde(control_num, control_denum, mde, bootstrap_iterations)\n    pvals.update({w: pval})\n    if pval<0.05:\n      pval_counter+=1\n    else:\n      pval_counter=0\n    \n  print ('week=',w,'; pval=',pval)\n  return pval, w, pval_counter, s_size, pvals\n\n    \n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6da6cb6b-e4e7-40c3-b04b-610dd07a0d50","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ab_tests_related_functions","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2772068}},"nbformat":4,"nbformat_minor":0}
